{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QR Code Malware Classifier üîç\n",
    "\n",
    "**Binary Classification: Benign vs Malicious QR Codes**\n",
    "\n",
    "[![Open In Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/)\n",
    "[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)\n",
    "[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)\n",
    "\n",
    "## üöÄ Features\n",
    "\n",
    "- **Mixed Precision Training (FP16)** - 2-3x speedup on GPU\n",
    "- **EfficientNet-B3** - State-of-the-art architecture with transfer learning\n",
    "- **Advanced Augmentation** - Simulates real-world phone camera conditions\n",
    "- **Progressive Fine-tuning** - Optimized learning strategy\n",
    "- **Auto-checkpointing** - Resume training after interruptions\n",
    "- **Cross-platform** - Works on Kaggle, Colab, and local environments\n",
    "\n",
    "## üìã Requirements\n",
    "\n",
    "```python\n",
    "torch>=2.0.0\n",
    "torchvision>=0.15.0\n",
    "numpy>=1.24.0\n",
    "pillow>=9.5.0\n",
    "scikit-learn>=1.3.0\n",
    "matplotlib>=3.7.0\n",
    "seaborn>=0.12.0\n",
    "tqdm>=4.65.0\n",
    "```\n",
    "\n",
    "## üìÇ Dataset Structure\n",
    "\n",
    "```\n",
    "QR codes/\n",
    "‚îú‚îÄ‚îÄ benign/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ benign/      # Benign QR code images\n",
    "‚îî‚îÄ‚îÄ malicious/\n",
    "    ‚îî‚îÄ‚îÄ malicious/   # Malicious QR code images\n",
    "```\n",
    "\n",
    "**Dataset:** [Benign and Malicious QR Codes](https://www.kaggle.com/datasets/samahsadiq/benign-and-malicious-qr-codes)\n",
    "\n",
    "## ‚öôÔ∏è Configuration\n",
    "\n",
    "- **Model:** EfficientNet-B3\n",
    "- **Image Size:** 256√ó256\n",
    "- **Batch Size:** 32 (effective: 64 with gradient accumulation)\n",
    "- **Epochs:** 25 (adjustable)\n",
    "- **Learning Rate:** 5e-4 with warmup + cosine annealing\n",
    "\n",
    "## üéØ Expected Results\n",
    "\n",
    "- **Accuracy:** 68-75% on test set\n",
    "- **Training Time:** ~45-60 minutes on Kaggle T4 GPU\n",
    "- **Inference:** <50ms per image\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** This notebook automatically detects your environment (Kaggle/Colab/Local) and adjusts paths accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Quick Start Guide\n",
    "\n",
    "### For Kaggle Users:\n",
    "1. Click **\"+ Add Data\"** ‚Üí Search for **\"benign-and-malicious-qr-codes\"**\n",
    "2. Enable **GPU**: Settings ‚Üí Accelerator ‚Üí GPU T4\n",
    "3. Run all cells in order (1 ‚Üí 18)\n",
    "\n",
    "### For Google Colab Users:\n",
    "1. Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU\n",
    "2. Upload dataset or mount Google Drive\n",
    "3. Update `DATA_DIR` in Cell 2 if needed\n",
    "4. Run all cells in order\n",
    "\n",
    "### For Local Users:\n",
    "1. Download dataset from [Kaggle](https://www.kaggle.com/datasets/samahsadiq/benign-and-malicious-qr-codes)\n",
    "2. Extract to `./QR codes/` in the same directory\n",
    "3. Install requirements: `pip install -r requirements.txt`\n",
    "4. Run cells in order\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Cell Execution Order\n",
    "\n",
    "| Cell | Description | Required |\n",
    "|------|-------------|----------|\n",
    "| 1-2 | Setup & Environment Detection | ‚úÖ Yes |\n",
    "| 3 | Hyperparameters Configuration | ‚úÖ Yes |\n",
    "| 4-7 | Data Loading & Model Creation | ‚úÖ Yes |\n",
    "| 8 | Resume Training (Optional) | ‚ö†Ô∏è Only if resuming |\n",
    "| 9-11 | Training Loop | ‚úÖ Yes |\n",
    "| 12 | Training Visualization | ‚úÖ Yes |\n",
    "| 13-16 | Evaluation & Results | ‚úÖ Yes |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T18:43:48.494898Z",
     "iopub.status.busy": "2025-11-10T18:43:48.494605Z",
     "iopub.status.idle": "2025-11-10T18:43:48.552605Z",
     "shell.execute_reply": "2025-11-10T18:43:48.551975Z",
     "shell.execute_reply.started": "2025-11-10T18:43:48.494876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üìå SETUP & REPRODUCIBILITY\n",
    "# ============================================================================\n",
    "# Cross-platform setup - auto-detects Kaggle, Google Colab, or Local environment\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ============================================================================\n",
    "# üåç ENVIRONMENT DETECTION (Kaggle / Colab / Local)\n",
    "# ============================================================================\n",
    "\n",
    "IS_KAGGLE = os.path.exists('/kaggle/input')\n",
    "IS_COLAB = 'COLAB_GPU' in os.environ\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    # Kaggle environment\n",
    "    BASE_DIR = '/kaggle/working'\n",
    "    DATA_DIR = '/kaggle/input/benign-and-malicious-qr-codes/QR codes'\n",
    "    print('üåê Environment: Kaggle')\n",
    "    print('üí° Make sure you added the dataset:')\n",
    "    print('   https://www.kaggle.com/datasets/samahsadiq/benign-and-malicious-qr-codes')\n",
    "    \n",
    "elif IS_COLAB:\n",
    "    # Google Colab environment\n",
    "    BASE_DIR = '/content'\n",
    "    DATA_DIR = '/content/QR codes'\n",
    "    print('üåê Environment: Google Colab')\n",
    "    print('üí° Upload your dataset or mount Google Drive:')\n",
    "    print('   from google.colab import drive')\n",
    "    print('   drive.mount(\"/content/drive\")')\n",
    "    print('   DATA_DIR = \"/content/drive/MyDrive/QR codes\"')\n",
    "    \n",
    "else:\n",
    "    # Local environment - automatically detect current directory\n",
    "    BASE_DIR = os.getcwd()\n",
    "    DATA_DIR = os.path.join(BASE_DIR, 'QR codes')\n",
    "    print('üíª Environment: Local')\n",
    "    print(f'üìÅ Working directory: {BASE_DIR}')\n",
    "    print('üí° Place your \"QR codes\" folder in the current directory')\n",
    "\n",
    "ARTIFACTS_DIR = os.path.join(BASE_DIR, 'artifacts')\n",
    "os.makedirs(ARTIFACTS_DIR, exist_ok=True)\n",
    "\n",
    "# ============================================================================\n",
    "# üìÇ VERIFY DATASET\n",
    "# ============================================================================\n",
    "\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print(f'\\n‚ùå ERROR: Data directory not found!')\n",
    "    print(f'   Expected location: {DATA_DIR}')\n",
    "    print(f'\\n\udce5 How to get the dataset:')\n",
    "    \n",
    "    if IS_KAGGLE:\n",
    "        print('   1. Click \"+ Add Data\" button on the right')\n",
    "        print('   2. Search: \"benign-and-malicious-qr-codes\"')\n",
    "        print('   3. Add the dataset by samahsadiq')\n",
    "        \n",
    "    elif IS_COLAB:\n",
    "        print('   1. Download from: https://www.kaggle.com/datasets/samahsadiq/benign-and-malicious-qr-codes')\n",
    "        print('   2. Upload to Colab or mount Google Drive')\n",
    "        print('   3. Update DATA_DIR variable above')\n",
    "        \n",
    "    else:\n",
    "        print('   1. Download from: https://www.kaggle.com/datasets/samahsadiq/benign-and-malicious-qr-codes')\n",
    "        print(f'   2. Extract to: {DATA_DIR}')\n",
    "        print('   3. Verify structure: QR codes/benign/benign/ and QR codes/malicious/malicious/')\n",
    "    \n",
    "    raise FileNotFoundError(f'Data directory not found: {DATA_DIR}')\n",
    "\n",
    "print(f'\\n‚úÖ Data directory found: {DATA_DIR}')\n",
    "\n",
    "# ============================================================================\n",
    "# üî• GPU SETUP\n",
    "# ============================================================================\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'\\nüî• Device: {device}')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f'   GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
    "    print(f'   CUDA Version: {torch.version.cuda}')\n",
    "else:\n",
    "    print('   ‚ö†Ô∏è No GPU detected. Training will be SLOW!')\n",
    "    print('   üí° Enable GPU in Kaggle/Colab settings for faster training')\n",
    "\n",
    "print(f'\\nüìÇ Paths:')\n",
    "print(f'   Data: {DATA_DIR}')\n",
    "print(f'   Output: {ARTIFACTS_DIR}')\n",
    "print(f'\\n‚úÖ Setup complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T18:43:53.212335Z",
     "iopub.status.busy": "2025-11-10T18:43:53.211822Z",
     "iopub.status.idle": "2025-11-10T18:43:53.218707Z",
     "shell.execute_reply": "2025-11-10T18:43:53.217927Z",
     "shell.execute_reply.started": "2025-11-10T18:43:53.212308Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üìå CELL 3: HYPERPARAMETERS - Tuned for Kaggle GPU\n",
    "# ============================================================================\n",
    "# OPTIMIZATION: Optimized config for T4/P100/A100 GPUs\n",
    "\n",
    "# Model config\n",
    "IMG_SIZE = 256  # CHANGED: B3 works better with 256x256\n",
    "MODEL_NAME = 'efficientnet_b3'  # CHANGED: B3 for higher accuracy\n",
    "PRETRAINED = True\n",
    "\n",
    "# Training config\n",
    "BATCH_SIZE = 32  # OPTIMIZED: Good for T4/P100 (use 64 for A100)\n",
    "NUM_WORKERS = 2  # OPTIMIZED: Kaggle typically has 2 CPU cores\n",
    "EPOCHS = 25  # Production training - expect 68-75% accuracy\n",
    "LEARNING_RATE = 5e-4  # INCREASED: 3e-4 ‚Üí 5e-4 for faster learning\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# Advanced features\n",
    "USE_MIXED_PRECISION = True  # OPTIMIZATION: 2-3x speedup with FP16\n",
    "GRADIENT_ACCUMULATION_STEPS = 2  # OPTIMIZATION: Effective batch = 32*2 = 64\n",
    "WARMUP_EPOCHS = 1  # OPTIMIZATION: LR warmup for stability\n",
    "LABEL_SMOOTHING = 0.1  # OPTIMIZATION: Prevents overconfidence\n",
    "\n",
    "# Early stopping\n",
    "PATIENCE = 5  # Stop if no improvement for 5 epochs\n",
    "MIN_DELTA = 1e-4\n",
    "\n",
    "# Data split\n",
    "VAL_SPLIT = 0.20\n",
    "TEST_SPLIT = 0.10\n",
    "\n",
    "print('Configuration:')\n",
    "print(f'  Model: {MODEL_NAME}, Image Size: {IMG_SIZE}x{IMG_SIZE}')\n",
    "print(f'  Batch: {BATCH_SIZE} (effective: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS})')\n",
    "print(f'  Epochs: {EPOCHS}, LR: {LEARNING_RATE}')\n",
    "print(f'  Mixed Precision: {USE_MIXED_PRECISION}')\n",
    "print(f'  Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-10T18:57:28.551Z",
     "iopub.execute_input": "2025-11-10T18:43:56.669970Z",
     "iopub.status.busy": "2025-11-10T18:43:56.669399Z"
    },
    "id": "R1cc2j7U9Klg",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üìå CELL 4: ULTRA-FAST DATA LOADING ‚ö° (2-3 minutes for 200K images!)\n",
    "# ============================================================================\n",
    "# OPTIMIZATION: Blazing fast collection with minimal validation + caching\n",
    "\n",
    "from PIL import Image, ImageFile\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True  # Handle corrupted images gracefully\n",
    "\n",
    "image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\", \".tiff\", \".webp\"}\n",
    "\n",
    "# FIXED: Double nesting - benign/benign/ and malicious/malicious/\n",
    "benign_dir = os.path.join(DATA_DIR, 'benign', 'benign')\n",
    "malicious_dir = os.path.join(DATA_DIR, 'malicious', 'malicious')\n",
    "\n",
    "print(f'\\nüìÅ Looking for data in:')\n",
    "print(f'   Benign: {benign_dir}')\n",
    "print(f'   Malicious: {malicious_dir}')\n",
    "\n",
    "# Check if directories exist\n",
    "if not os.path.exists(benign_dir):\n",
    "    print(f'\\n‚ùå ERROR: Benign directory not found!')\n",
    "    print(f'   Expected: {benign_dir}')\n",
    "    raise FileNotFoundError(f'Benign directory not found: {benign_dir}')\n",
    "\n",
    "if not os.path.exists(malicious_dir):\n",
    "    print(f'\\n‚ùå ERROR: Malicious directory not found!')\n",
    "    print(f'   Expected: {malicious_dir}')\n",
    "    raise FileNotFoundError(f'Malicious directory not found: {malicious_dir}')\n",
    "\n",
    "def collect_images_ultra_fast(directory, label_name, label_value):\n",
    "    \"\"\"‚ö° ULTRA FAST collection - no validation, just path + size check\"\"\"\n",
    "    files = []\n",
    "    dir_path = Path(directory)\n",
    "    \n",
    "    # Quick scan for all image files\n",
    "    print(f'   üîç Scanning {label_name} directory...')\n",
    "    all_files = []\n",
    "    for ext in image_extensions:\n",
    "        all_files.extend(dir_path.glob(f'**/*{ext}'))\n",
    "    \n",
    "    print(f'   ‚ö° Found {len(all_files):,} {label_name} files - Processing...')\n",
    "    \n",
    "    # OPTIMIZATION: Accept all files without size check (fastest possible)\n",
    "    for fp in tqdm(all_files, desc=f'   Loading {label_name}', unit='img', \n",
    "                   ncols=80, leave=False):\n",
    "        try:\n",
    "            # Just add the path - errors handled by Dataset class during training\n",
    "            files.append((str(fp), label_value))\n",
    "        except:\n",
    "            pass  # Skip files with permission/access errors\n",
    "    \n",
    "    print(f'   ‚úÖ Loaded {len(files):,} {label_name} images')\n",
    "    return files\n",
    "\n",
    "# Check for cached file list (saves ~2 minutes on reruns)\n",
    "cache_file = os.path.join(ARTIFACTS_DIR, 'dataset_cache.pkl')\n",
    "use_cache = os.path.exists(cache_file)\n",
    "\n",
    "if use_cache:\n",
    "    print('\\nüíæ Found cached dataset! Loading from cache...')\n",
    "    try:\n",
    "        with open(cache_file, 'rb') as f:\n",
    "            all_files = pickle.load(f)\n",
    "        print(f'   ‚úÖ Loaded {len(all_files):,} images from cache (instant!)')\n",
    "    except:\n",
    "        print('   ‚ö†Ô∏è Cache corrupted, rebuilding...')\n",
    "        use_cache = False\n",
    "\n",
    "if not use_cache:\n",
    "    print('\\n' + '='*70)\n",
    "    print('‚ö° ULTRA-FAST LOADING (No validation - errors handled in Dataset)')\n",
    "    print('='*70)\n",
    "    \n",
    "    print(f'\\nüìÇ Processing BENIGN images from: {benign_dir}')\n",
    "    benign_files = collect_images_ultra_fast(benign_dir, 'benign', 0)\n",
    "    \n",
    "    print(f'\\nüìÇ Processing MALICIOUS images from: {malicious_dir}')\n",
    "    malicious_files = collect_images_ultra_fast(malicious_dir, 'malicious', 1)\n",
    "    \n",
    "    all_files = benign_files + malicious_files\n",
    "    \n",
    "    # Save cache for next run\n",
    "    print(f'\\nüíæ Saving dataset cache for future runs...')\n",
    "    try:\n",
    "        with open(cache_file, 'wb') as f:\n",
    "            pickle.dump(all_files, f)\n",
    "        print(f'   ‚úÖ Cache saved! Next run will be instant.')\n",
    "    except:\n",
    "        print(f'   ‚ö†Ô∏è Could not save cache (not critical)')\n",
    "    \n",
    "    print(f'\\n‚úÖ Dataset Summary:')\n",
    "    print(f'   Benign: {len(benign_files):,}')\n",
    "    print(f'   Malicious: {len(malicious_files):,}')\n",
    "    print(f'   Total: {len(all_files):,}')\n",
    "    print(f'   ‚ö° Loading time: 2-3 minutes (vs 5-8 min before)')\n",
    "    print(f'   üî• Next runs: <5 seconds with cache!')\n",
    "\n",
    "if len(all_files) == 0:\n",
    "    print(f'\\n‚ùå ERROR: No images found in dataset!')\n",
    "    print(f'   Please check that your images are in:')\n",
    "    print(f'   {benign_dir}')\n",
    "    print(f'   {malicious_dir}')\n",
    "    raise ValueError('No images found in dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-10T18:57:28.552Z"
    },
    "id": "hg5MGoaw9V7L",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üìå CELL 5: TRAIN/VAL/TEST SPLIT\n",
    "# ============================================================================\n",
    "# OPTIMIZATION: Stratified split with sklearn\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features and labels\n",
    "file_paths = [fp for fp, _ in all_files]\n",
    "labels = [lbl for _, lbl in all_files]\n",
    "\n",
    "# Split: Train+Val / Test\n",
    "train_val_files, test_files, train_val_labels, test_labels = train_test_split(\n",
    "    file_paths, labels, test_size=TEST_SPLIT, stratify=labels, random_state=SEED\n",
    ")\n",
    "\n",
    "# Split: Train / Val\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(\n",
    "    train_val_files, train_val_labels, \n",
    "    test_size=VAL_SPLIT/(1-TEST_SPLIT), \n",
    "    stratify=train_val_labels, \n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# Create pairs\n",
    "train_pairs = list(zip(train_files, train_labels))\n",
    "val_pairs = list(zip(val_files, val_labels))\n",
    "test_pairs = list(zip(test_files, test_labels))\n",
    "\n",
    "random.shuffle(train_pairs)\n",
    "random.shuffle(val_pairs)\n",
    "random.shuffle(test_pairs)\n",
    "\n",
    "print('Data Split:')\n",
    "print(f'  Train: {len(train_pairs):,} {Counter(train_labels)}')\n",
    "print(f'  Val: {len(val_pairs):,} {Counter(val_labels)}')\n",
    "print(f'  Test: {len(test_pairs):,} {Counter(test_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-10T18:57:28.552Z"
    },
    "id": "ohdf7-S_9Xb9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üìå CELL 6: DATASET & DATALOADERS\n",
    "# ============================================================================\n",
    "# OPTIMIZATION: Advanced augmentation + Phone Camera Simulation + Fast loading\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import ImageFilter, ImageEnhance\n",
    "import random\n",
    "\n",
    "class PhoneCameraQRNoise:\n",
    "    \"\"\"üì± Simulates imperfect phone camera scanning of QR codes\"\"\"\n",
    "    def __init__(self, p=0.7):\n",
    "        self.p = p\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        \"\"\"Apply realistic phone camera degradation effects\"\"\"\n",
    "        if random.random() < self.p:\n",
    "            # 1. LIGHTING ISSUES (very common with phone cameras)\n",
    "            if random.random() < 0.7:\n",
    "                # Uneven lighting, shadows, glare\n",
    "                img = transforms.functional.adjust_brightness(img, random.uniform(0.6, 1.4))\n",
    "                img = transforms.functional.adjust_contrast(img, random.uniform(0.7, 1.5))\n",
    "            \n",
    "            # 2. FOCUS/MOTION BLUR (shaky hands, autofocus issues)\n",
    "            if random.random() < 0.5:\n",
    "                blur_radius = random.choice([0.5, 1, 1.5, 2])\n",
    "                img = img.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n",
    "            \n",
    "            # 3. CAMERA NOISE (low light conditions)\n",
    "            if random.random() < 0.3:\n",
    "                enhancer = ImageEnhance.Sharpness(img)\n",
    "                img = enhancer.enhance(random.uniform(0.5, 1.5))\n",
    "            \n",
    "            # 4. JPEG COMPRESSION (phone saves as compressed JPEG)\n",
    "            if random.random() < 0.4:\n",
    "                from io import BytesIO\n",
    "                buf = BytesIO()\n",
    "                # Phone cameras typically use 75-95 quality\n",
    "                img.save(buf, format='JPEG', quality=random.randint(60, 95))\n",
    "                buf.seek(0)\n",
    "                img = Image.open(buf)\n",
    "            \n",
    "            # 5. COLOR CAST (different phone camera sensors)\n",
    "            if random.random() < 0.3:\n",
    "                img = transforms.functional.adjust_saturation(img, random.uniform(0.8, 1.2))\n",
    "                img = transforms.functional.adjust_hue(img, random.uniform(-0.05, 0.05))\n",
    "        \n",
    "        return img\n",
    "\n",
    "class QRDataset(Dataset):\n",
    "    \"\"\"Error-resistant dataset with fallback for corrupted images\"\"\"\n",
    "    def __init__(self, file_label_pairs, transform=None):\n",
    "        self.files = [p for p, _ in file_label_pairs]\n",
    "        self.labels = [lbl for _, lbl in file_label_pairs]\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            image = Image.open(self.files[idx]).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image, self.labels[idx]\n",
    "        except Exception:\n",
    "            # Fallback to black image on error\n",
    "            if self.transform:\n",
    "                black_img = Image.new('RGB', (IMG_SIZE, IMG_SIZE), (0, 0, 0))\n",
    "                return self.transform(black_img), self.labels[idx]\n",
    "            return torch.zeros(3, IMG_SIZE, IMG_SIZE), self.labels[idx]\n",
    "\n",
    "# OPTIMIZATION: Moderate augmentation - reduced intensity for better QR pattern learning\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.3),  # REDUCED: 0.5 ‚Üí 0.3\n",
    "    transforms.RandomVerticalFlip(p=0.2),     # REDUCED: 0.3 ‚Üí 0.2\n",
    "    transforms.RandomRotation(10),            # REDUCED: 15 ‚Üí 10 degrees\n",
    "    transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.08, hue=0.03),  # REDUCED\n",
    "    PhoneCameraQRNoise(p=0.5),  # REDUCED: 0.7 ‚Üí 0.5 (less aggressive)\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.95, 1.05)),  # REDUCED\n",
    "    transforms.RandomPerspective(distortion_scale=0.1, p=0.2),  # REDUCED: 0.2 ‚Üí 0.1\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.1, scale=(0.02, 0.08)),  # REDUCED: 0.2 ‚Üí 0.1\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = QRDataset(train_pairs, transform=train_transform)\n",
    "val_dataset = QRDataset(val_pairs, transform=val_transform)\n",
    "test_dataset = QRDataset(test_pairs, transform=val_transform)\n",
    "\n",
    "# OPTIMIZATION: Efficient data loading with prefetching\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True,\n",
    "    persistent_workers=True if NUM_WORKERS > 0 else False,\n",
    "    prefetch_factor=2 if NUM_WORKERS > 0 else None\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE * 2, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True,\n",
    "    persistent_workers=True if NUM_WORKERS > 0 else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE * 2, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n",
    "\n",
    "print(f'DataLoaders Ready:')\n",
    "print(f'  Train batches: {len(train_loader)}')\n",
    "print(f'  Val batches: {len(val_loader)}')\n",
    "print(f'  Test batches: {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-10T18:57:28.552Z"
    },
    "id": "8MZcAexI9ZQ8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üìå CELL 7: MODEL ARCHITECTURE\n",
    "# ============================================================================\n",
    "# OPTIMIZATION: EfficientNet with enhanced classification head (supports B2/B3/B4)\n",
    "\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class QRClassifier(nn.Module):\n",
    "    \"\"\"EfficientNet with custom head for binary classification\"\"\"\n",
    "    def __init__(self, model_name='efficientnet_b2', dropout_rate=0.3, hidden_units=256):\n",
    "        super(QRClassifier, self).__init__()\n",
    "        \n",
    "        # Load pretrained EfficientNet (supports B0-B7)\n",
    "        if model_name == 'efficientnet_b0':\n",
    "            self.backbone = models.efficientnet_b0(pretrained=PRETRAINED)\n",
    "        elif model_name == 'efficientnet_b2':\n",
    "            self.backbone = models.efficientnet_b2(pretrained=PRETRAINED)\n",
    "        elif model_name == 'efficientnet_b3':\n",
    "            self.backbone = models.efficientnet_b3(pretrained=PRETRAINED)\n",
    "        elif model_name == 'efficientnet_b4':\n",
    "            self.backbone = models.efficientnet_b4(pretrained=PRETRAINED)\n",
    "        else:\n",
    "            raise ValueError(f'Unsupported model: {model_name}')\n",
    "        \n",
    "        # Freeze backbone initially\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # OPTIMIZATION: Enhanced head with BatchNorm for stability\n",
    "        in_features = self.backbone.classifier[1].in_features\n",
    "        self.backbone.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(in_features, hidden_units),\n",
    "            nn.BatchNorm1d(hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate/2),\n",
    "            nn.Linear(hidden_units, 1)\n",
    "            # No sigmoid - using BCEWithLogitsLoss\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "    \n",
    "    def unfreeze_backbone(self, unfreeze_ratio=0.3):\n",
    "        \"\"\"Progressive unfreezing for fine-tuning\"\"\"\n",
    "        all_params = list(self.backbone.parameters())\n",
    "        n_unfreeze = int(len(all_params) * unfreeze_ratio)\n",
    "        \n",
    "        for param in all_params[-n_unfreeze:]:\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        n_trainable = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        print(f'Unfroze {unfreeze_ratio:.0%} of backbone ({n_trainable:,} trainable params)')\n",
    "\n",
    "# Initialize model with MODEL_NAME from Cell 3\n",
    "model = QRClassifier(model_name=MODEL_NAME, dropout_rate=0.3, hidden_units=256).to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'\\nModel: {MODEL_NAME.upper()}')\n",
    "print(f'  Total params: {total_params:,}')\n",
    "print(f'  Trainable params: {trainable_params:,}')\n",
    "print(f'  Frozen params: {total_params - trainable_params:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Optional: Resume Training from Checkpoint\n",
    "\n",
    "If your Kaggle session times out, you can resume training from the last saved checkpoint. Just run the cell below before the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üìå CELL 8 (OPTIONAL): RESUME FROM CHECKPOINT - Skip this for first run!\n",
    "# ============================================================================\n",
    "# Uncomment and run this cell BEFORE the training loop if you need to resume\n",
    "\n",
    "\"\"\"\n",
    "checkpoint_path = os.path.join(ARTIFACTS_DIR, 'last_checkpoint.pth')\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print('üì¶ Found checkpoint! Resuming training...')\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
    "    \n",
    "    start_epoch = checkpoint['epoch']\n",
    "    history = checkpoint['history']\n",
    "    best_val_acc = checkpoint['best_val_acc']\n",
    "    \n",
    "    print(f'‚úÖ Resumed from epoch {start_epoch}')\n",
    "    print(f'   Best val acc so far: {best_val_acc:.4f}')\n",
    "    print(f'   Will continue from epoch {start_epoch + 1}')\n",
    "    \n",
    "    # Update EPOCHS to continue\n",
    "    REMAINING_EPOCHS = EPOCHS - start_epoch\n",
    "    print(f'   {REMAINING_EPOCHS} epochs remaining')\n",
    "else:\n",
    "    print('No checkpoint found. Starting fresh training.')\n",
    "    start_epoch = 0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n",
    "    best_val_acc = 0.0\n",
    "\"\"\"\n",
    "\n",
    "print('üí° This cell is commented out. Uncomment if you need to resume training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T18:37:13.628552Z",
     "iopub.status.busy": "2025-11-10T18:37:13.628238Z",
     "iopub.status.idle": "2025-11-10T18:37:16.656667Z",
     "shell.execute_reply": "2025-11-10T18:37:16.655764Z",
     "shell.execute_reply.started": "2025-11-10T18:37:13.628526Z"
    },
    "id": "b0fXwfnH9hYN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üìå LOAD BEST MODEL & EVALUATE ON TEST SET\n",
    "# ============================================================================\n",
    "# ‚ö†Ô∏è Run this AFTER training (after the training loop completes)\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.cuda.amp import autocast\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "# Use paths from Cell 2 (already set based on environment)\n",
    "# ARTIFACTS_DIR and device are already defined from previous cells\n",
    "\n",
    "print('üì¶ Loading best model from training...')\n",
    "checkpoint_path = os.path.join(ARTIFACTS_DIR, 'best_model.pth')\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    print(f'‚úÖ Loaded best model:')\n",
    "    print(f'   Epoch: {checkpoint[\"epoch\"]}')\n",
    "    print(f'   Validation Acc: {checkpoint[\"val_acc\"]:.4f}')\n",
    "else:\n",
    "    print(f'‚ö†Ô∏è No checkpoint found at: {checkpoint_path}')\n",
    "    print(f'   Using current model state (may not be optimal)')\n",
    "\n",
    "# ============================================================================\n",
    "# EVALUATE ON TEST SET\n",
    "# ============================================================================\n",
    "\n",
    "print(f'\\nüß™ Evaluating on test set...')\n",
    "test_loss, test_acc, test_preds, test_labels, test_probs = validate_epoch(\n",
    "    model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "test_preds_binary = (np.array(test_probs) >= 0.5).astype(int).flatten()\n",
    "test_labels_binary = np.array(test_labels).astype(int).flatten()\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    test_labels_binary, test_preds_binary, average='binary'\n",
    ")\n",
    "roc_auc = roc_auc_score(test_labels_binary, test_probs)\n",
    "\n",
    "# Display results\n",
    "print(f'\\n{\"=\"*60}')\n",
    "print(f'üìä TEST SET RESULTS')\n",
    "print(f'{\"=\"*60}')\n",
    "print(f'  Accuracy:  {test_acc:.4f} ({test_acc*100:.2f}%)')\n",
    "print(f'  Precision: {precision:.4f}')\n",
    "print(f'  Recall:    {recall:.4f}')\n",
    "print(f'  F1-Score:  {f1:.4f}')\n",
    "print(f'  ROC-AUC:   {roc_auc:.4f}')\n",
    "print(f'{\"=\"*60}')\n",
    "\n",
    "# Class-wise breakdown\n",
    "benign_correct = sum((test_labels_binary == 0) & (test_preds_binary == 0))\n",
    "benign_total = sum(test_labels_binary == 0)\n",
    "malicious_correct = sum((test_labels_binary == 1) & (test_preds_binary == 1))\n",
    "malicious_total = sum(test_labels_binary == 1)\n",
    "\n",
    "print(f'\\nüìà Per-Class Performance:')\n",
    "print(f'  Benign:    {benign_correct}/{benign_total} ({benign_correct/benign_total*100:.1f}%)')\n",
    "print(f'  Malicious: {malicious_correct}/{malicious_total} ({malicious_correct/malicious_total*100:.1f}%)')\n",
    "print(f'\\n‚úÖ Evaluation complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-10T18:15:44.381807Z",
     "iopub.status.idle": "2025-11-10T18:15:44.382061Z",
     "shell.execute_reply": "2025-11-10T18:15:44.381956Z",
     "shell.execute_reply.started": "2025-11-10T18:15:44.381945Z"
    },
    "id": "uZfXL4ql9jUp",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üìå CELL 14: CONFUSION MATRIX & CLASSIFICATION REPORT\n",
    "# ============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_labels_binary, test_preds_binary)\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(test_labels_binary, test_preds_binary, \n",
    "                          target_names=['Benign', 'Malicious'], digits=4))\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Counts\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Benign', 'Malicious'],\n",
    "            yticklabels=['Benign', 'Malicious'])\n",
    "axes[0].set_ylabel('True Label', fontsize=12)\n",
    "axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[0].set_title('Confusion Matrix (Counts)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Normalized\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Blues', ax=axes[1],\n",
    "            xticklabels=['Benign', 'Malicious'],\n",
    "            yticklabels=['Benign', 'Malicious'])\n",
    "axes[1].set_ylabel('True Label', fontsize=12)\n",
    "axes[1].set_xlabel('Predicted Label', fontsize=12)\n",
    "axes[1].set_title('Confusion Matrix (Normalized)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(ARTIFACTS_DIR, 'confusion_matrix.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-10T18:15:44.383655Z",
     "iopub.status.idle": "2025-11-10T18:15:44.383901Z",
     "shell.execute_reply": "2025-11-10T18:15:44.383796Z",
     "shell.execute_reply.started": "2025-11-10T18:15:44.383785Z"
    },
    "id": "nrBrtYTF-Hhe",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üìå CELL 15: SAVE FINAL MODEL & ARTIFACTS\n",
    "# ============================================================================\n",
    "\n",
    "# Save complete model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_name': MODEL_NAME,\n",
    "    'img_size': IMG_SIZE,\n",
    "    'test_acc': test_acc,\n",
    "    'test_loss': test_loss,\n",
    "    'history': history,\n",
    "}, os.path.join(ARTIFACTS_DIR, 'qr_classifier_final.pth'))\n",
    "\n",
    "# Save weights only\n",
    "torch.save(model.state_dict(), os.path.join(ARTIFACTS_DIR, 'model_weights.pth'))\n",
    "\n",
    "# Save training history\n",
    "import pandas as pd\n",
    "pd.DataFrame(history).to_csv(os.path.join(ARTIFACTS_DIR, 'history.csv'), index=False)\n",
    "\n",
    "# Save predictions\n",
    "pd.DataFrame({\n",
    "    'true_label': test_labels_binary,\n",
    "    'predicted_label': test_preds_binary,\n",
    "    'probability': np.array(test_probs).flatten(),\n",
    "    'correct': test_labels_binary == test_preds_binary\n",
    "}).to_csv(os.path.join(ARTIFACTS_DIR, 'test_predictions.csv'), index=False)\n",
    "\n",
    "print(f'\\n‚úÖ All artifacts saved to: {ARTIFACTS_DIR}')\n",
    "print(f'  - best_model.pth')\n",
    "print(f'  - qr_classifier_final.pth')\n",
    "print(f'  - model_weights.pth')\n",
    "print(f'  - history.csv')\n",
    "print(f'  - training_history.png')\n",
    "print(f'  - confusion_matrix.png')\n",
    "print(f'  - test_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-10T18:15:44.384707Z",
     "iopub.status.idle": "2025-11-10T18:15:44.385037Z",
     "shell.execute_reply": "2025-11-10T18:15:44.384860Z",
     "shell.execute_reply.started": "2025-11-10T18:15:44.384846Z"
    },
    "id": "iIyd4mM9-LCJ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üìå CELL 16: INFERENCE ON SAMPLE IMAGES\n",
    "# ============================================================================\n",
    "\n",
    "def predict_image(image_path, model, device):\n",
    "    \"\"\"Predict single image\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_tensor = val_transform(img).unsqueeze(0).to(device)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            with autocast(enabled=USE_MIXED_PRECISION):\n",
    "                output = model(img_tensor)\n",
    "                prob = torch.sigmoid(output).item()\n",
    "        \n",
    "        pred_label = \"Malicious\" if prob >= 0.5 else \"Benign\"\n",
    "        confidence = max(prob, 1-prob)\n",
    "        \n",
    "        return pred_label, prob, confidence\n",
    "    except Exception as e:\n",
    "        print(f'Error: {e}')\n",
    "        return None, None, None\n",
    "\n",
    "# Test on random samples\n",
    "print('Testing inference on random samples:\\n')\n",
    "\n",
    "sample_indices = random.sample(range(len(test_pairs)), min(5, len(test_pairs)))\n",
    "\n",
    "for idx in sample_indices:\n",
    "    img_path, true_label = test_pairs[idx]\n",
    "    true_label_str = \"Malicious\" if true_label == 1 else \"Benign\"\n",
    "    \n",
    "    pred_label, prob, confidence = predict_image(img_path, model, device)\n",
    "    \n",
    "    if pred_label:\n",
    "        correct = \"‚úÖ\" if pred_label == true_label_str else \"‚ùå\"\n",
    "        print(f'{os.path.basename(img_path)}')\n",
    "        print(f'  True: {true_label_str} | Pred: {pred_label} ({confidence:.2%}) {correct}')\n",
    "\n",
    "print('\\n‚úÖ Inference test complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Quick Reference: Optimization Summary\n",
    "\n",
    "### Key Improvements Made:\n",
    "1. **Model**: EfficientNet-B0 ‚Üí **B2** (better accuracy, +1-2%)\n",
    "2. **Image Size**: 128 ‚Üí **224** pixels (better for B2 architecture)\n",
    "3. **Mixed Precision**: Added FP16 training (**2-3x speedup**)\n",
    "4. **Augmentation**: Enhanced with perspective, affine, erasing\n",
    "5. **Optimizer**: Adam ‚Üí **AdamW** with weight decay\n",
    "6. **Scheduler**: Added **warmup + cosine annealing**\n",
    "7. **Loss**: BCELoss ‚Üí **BCEWithLogitsLoss** (more stable)\n",
    "8. **Regularization**: Label smoothing, BatchNorm in head\n",
    "9. **Training**: Gradient accumulation, progressive fine-tuning\n",
    "10. **Monitoring**: Early stopping, best model checkpointing\n",
    "\n",
    "### To Adjust for Production:\n",
    "```python\n",
    "# In cell 2, change:\n",
    "EPOCHS = 25              # Increase from 5 to 25-30\n",
    "PATIENCE = 5             # Increase from 3 to 5\n",
    "BATCH_SIZE = 64          # If using A100, increase to 64\n",
    "```\n",
    "\n",
    "### For Maximum Accuracy (slower):\n",
    "```python\n",
    "MODEL_NAME = 'efficientnet_b3'  # Use B3 or B4\n",
    "IMG_SIZE = 256                   # Increase resolution\n",
    "EPOCHS = 40                      # More training\n",
    "```\n",
    "\n",
    "### For Faster Training (slight accuracy loss):\n",
    "```python\n",
    "MODEL_NAME = 'efficientnet_b0'  # Use B0\n",
    "IMG_SIZE = 128                   # Reduce resolution\n",
    "BATCH_SIZE = 64                  # Increase batch size\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T10:26:41.342758Z",
     "iopub.status.busy": "2025-11-10T10:26:41.342463Z",
     "iopub.status.idle": "2025-11-10T10:26:41.351964Z",
     "shell.execute_reply": "2025-11-10T10:26:41.351250Z",
     "shell.execute_reply.started": "2025-11-10T10:26:41.342737Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üìå CELL 9: TRAINING SETUP (Optimizer, Loss, Scheduler)\n",
    "# ============================================================================\n",
    "# OPTIMIZATION: Modern training components (AdamW, Cosine LR, Mixed Precision)\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# OPTIMIZATION: BCEWithLogitsLoss for numerical stability\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# OPTIMIZATION: AdamW with weight decay\n",
    "optimizer = optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# OPTIMIZATION: Learning rate scheduling with warmup\n",
    "warmup_scheduler = optim.lr_scheduler.LinearLR(\n",
    "    optimizer, start_factor=0.1, end_factor=1.0, total_iters=WARMUP_EPOCHS\n",
    ")\n",
    "\n",
    "main_scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=EPOCHS - WARMUP_EPOCHS, eta_min=LEARNING_RATE * 0.01\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.SequentialLR(\n",
    "    optimizer, schedulers=[warmup_scheduler, main_scheduler], milestones=[WARMUP_EPOCHS]\n",
    ")\n",
    "\n",
    "# OPTIMIZATION: Mixed precision scaler for FP16 training\n",
    "scaler = GradScaler(enabled=USE_MIXED_PRECISION)\n",
    "\n",
    "print('Training Setup:')\n",
    "print(f'  Loss: BCEWithLogitsLoss')\n",
    "print(f'  Optimizer: AdamW (lr={LEARNING_RATE}, wd={WEIGHT_DECAY})')\n",
    "print(f'  Scheduler: Warmup + CosineAnnealing')\n",
    "print(f'  Mixed Precision: {USE_MIXED_PRECISION}')\n",
    "print(f'  Gradient Accumulation: {GRADIENT_ACCUMULATION_STEPS} steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T10:26:46.861422Z",
     "iopub.status.busy": "2025-11-10T10:26:46.861131Z",
     "iopub.status.idle": "2025-11-10T10:26:46.874164Z",
     "shell.execute_reply": "2025-11-10T10:26:46.873459Z",
     "shell.execute_reply.started": "2025-11-10T10:26:46.861400Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üìå CELL 10: TRAINING FUNCTIONS (train_epoch & validate_epoch)\n",
    "# ============================================================================\n",
    "# OPTIMIZATION: Modular training functions with mixed precision\n",
    "\n",
    "import time\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer, scaler, device, accumulation_steps=1):\n",
    "    \"\"\"Train one epoch with gradient accumulation and mixed precision\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training', leave=False)\n",
    "    for batch_idx, (images, labels) in enumerate(pbar):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.float().unsqueeze(1).to(device, non_blocking=True)\n",
    "        \n",
    "        # OPTIMIZATION: Label smoothing (ONLY for loss calculation)\n",
    "        labels_smoothed = labels\n",
    "        if LABEL_SMOOTHING > 0:\n",
    "            labels_smoothed = labels * (1 - LABEL_SMOOTHING) + 0.5 * LABEL_SMOOTHING\n",
    "        \n",
    "        # OPTIMIZATION: Mixed precision forward pass\n",
    "        with autocast(enabled=USE_MIXED_PRECISION):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels_smoothed) / accumulation_steps\n",
    "        \n",
    "        # Backward with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # OPTIMIZATION: Gradient accumulation\n",
    "        if (batch_idx + 1) % accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Metrics (use ORIGINAL labels, not smoothed)\n",
    "        with torch.no_grad():\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            predicted = (probs >= 0.5).float()\n",
    "            correct += (predicted == labels).sum().item()  # Compare to original labels!\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        running_loss += loss.item() * accumulation_steps * images.size(0)\n",
    "        pbar.set_postfix({'loss': f'{loss.item() * accumulation_steps:.4f}'})\n",
    "    \n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "    \"\"\"Validate one epoch\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Validation', leave=False):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.float().unsqueeze(1).to(device, non_blocking=True)\n",
    "            \n",
    "            with autocast(enabled=USE_MIXED_PRECISION):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            probs = torch.sigmoid(outputs)\n",
    "            predicted = (probs >= 0.5).float()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    return running_loss / total, correct / total, all_preds, all_labels, all_probs\n",
    "\n",
    "print('Training functions ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T10:26:51.193549Z",
     "iopub.status.busy": "2025-11-10T10:26:51.193266Z",
     "iopub.status.idle": "2025-11-10T17:26:30.561958Z",
     "shell.execute_reply": "2025-11-10T17:26:30.560899Z",
     "shell.execute_reply.started": "2025-11-10T10:26:51.193528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üìå CELL 11: MAIN TRAINING LOOP (This will train for 2 epochs!)\n",
    "# ============================================================================\n",
    "# OPTIMIZATION: Complete training with all features + automatic checkpointing\n",
    "\n",
    "best_val_acc = 0.0\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'lr': []}\n",
    "\n",
    "print(f'\\n{\"=\"*70}')\n",
    "print(f'Training on {device} - {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"}')\n",
    "print(f'{\"=\"*70}\\n')\n",
    "\n",
    "training_start = time.time()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model, train_loader, criterion, optimizer, scaler, device, GRADIENT_ACCUMULATION_STEPS\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, _, _, _ = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Learning rate\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step()\n",
    "    \n",
    "    # History\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    # Print results\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS} ({epoch_time:.1f}s) | LR: {current_lr:.2e}')\n",
    "    print(f'  Train - Loss: {train_loss:.4f} | Acc: {train_acc:.4f}')\n",
    "    print(f'  Val   - Loss: {val_loss:.4f} | Acc: {val_acc:.4f}', end='')\n",
    "    \n",
    "    # OPTIMIZATION: Save checkpoint EVERY epoch (in case of Kaggle timeout)\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'scaler_state_dict': scaler.state_dict(),\n",
    "        'val_acc': val_acc,\n",
    "        'val_loss': val_loss,\n",
    "        'history': history,\n",
    "        'best_val_acc': best_val_acc\n",
    "    }\n",
    "    \n",
    "    # Save last checkpoint (in case we need to resume)\n",
    "    torch.save(checkpoint, os.path.join(ARTIFACTS_DIR, 'last_checkpoint.pth'))\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_val_loss = val_loss\n",
    "        \n",
    "        torch.save(checkpoint, os.path.join(ARTIFACTS_DIR, 'best_model.pth'))\n",
    "        \n",
    "        print(f' ‚úÖ BEST', end='')\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f' (patience: {patience_counter}/{PATIENCE})', end='')\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # OPTIMIZATION: Progressive unfreezing BEFORE early stopping check\n",
    "    # CHANGED: Unfreeze at epoch 5 to give backbone time to learn before patience runs out\n",
    "    if EPOCHS > 5 and epoch + 1 == 5 and trainable_params < total_params * 0.5:\n",
    "        print(f'\\nüîì Unfreezing backbone for fine-tuning...')\n",
    "        model.unfreeze_backbone(0.3)\n",
    "        \n",
    "        # Reset optimizer with lower LR\n",
    "        optimizer = optim.AdamW(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            lr=LEARNING_RATE * 0.1,\n",
    "            weight_decay=WEIGHT_DECAY\n",
    "        )\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=EPOCHS - epoch - 1, eta_min=LEARNING_RATE * 0.001\n",
    "        )\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        \n",
    "        # CRITICAL: Reset patience counter when unfreezing to give model time to adapt\n",
    "        patience_counter = 0\n",
    "        print(f'‚úÖ Patience reset! Model has {PATIENCE} epochs to improve with unfrozen backbone\\n')\n",
    "    \n",
    "    # Early stopping check AFTER unfreezing\n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(f'\\n‚ö†Ô∏è Early stopping at epoch {epoch+1}')\n",
    "        break\n",
    "    \n",
    "    print()\n",
    "\n",
    "total_time = time.time() - training_start\n",
    "\n",
    "print(f'{\"=\"*70}')\n",
    "print(f'Training Complete!')\n",
    "print(f'  Time: {total_time/60:.2f} minutes')\n",
    "print(f'  Best Val Acc: {best_val_acc:.4f}')\n",
    "print(f'  Best Val Loss: {best_val_loss:.4f}')\n",
    "print(f'{\"=\"*70}')\n",
    "print(f'\\nüíæ Checkpoints saved:')\n",
    "print(f'   - best_model.pth (best validation accuracy)')\n",
    "print(f'   - last_checkpoint.pth (resume from last epoch if interrupted)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T18:07:23.130826Z",
     "iopub.status.busy": "2025-11-10T18:07:23.130117Z",
     "iopub.status.idle": "2025-11-10T18:07:35.047218Z",
     "shell.execute_reply": "2025-11-10T18:07:35.046539Z",
     "shell.execute_reply.started": "2025-11-10T18:07:23.130779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# üìå CELL 12: VISUALIZATION - Training History Graphs\n",
    "# ============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "epochs_range = range(1, len(history['train_acc']) + 1)\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(epochs_range, history['train_acc'], 'b-o', label='Train', linewidth=2)\n",
    "axes[0].plot(epochs_range, history['val_acc'], 'r-s', label='Val', linewidth=2)\n",
    "axes[0].axhline(y=best_val_acc, color='g', linestyle='--', alpha=0.7, label=f'Best ({best_val_acc:.4f})')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(epochs_range, history['train_loss'], 'b-o', label='Train', linewidth=2)\n",
    "axes[1].plot(epochs_range, history['val_loss'], 'r-s', label='Val', linewidth=2)\n",
    "axes[1].axhline(y=best_val_loss, color='g', linestyle='--', alpha=0.7, label=f'Best ({best_val_loss:.4f})')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Loss', fontsize=12)\n",
    "axes[1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "# Learning Rate\n",
    "axes[2].plot(epochs_range, history['lr'], 'g-o', linewidth=2)\n",
    "axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "axes[2].set_ylabel('Learning Rate', fontsize=12)\n",
    "axes[2].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "axes[2].set_yscale('log')\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(ARTIFACTS_DIR, 'training_history.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'Best validation accuracy: {best_val_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2378694,
     "sourceId": 4012771,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 496699,
     "modelInstanceId": 481103,
     "sourceId": 638227,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
